{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression \n",
    "\n",
    "A sigmoid function is used to calculate the positive or negative output of a given function\n",
    "\n",
    "Visually, the sigmoid function has this form and it approaches zero as the dot product of $ \\theta^T \\cdot X $ over here, approaches minus infinity and one as it approaches infinity. For classification, a threshold is needed. Usually, it is set to be 0.5 and this value corresponds to a dot product between Theta transpose and X equal to zero. So whenever the dot product is greater or equal than zero, the prediction is positive, and whenever the dot product is less than zero, the prediction is negative.\n",
    "\n",
    "![Logistic Regression](Images/LogisticRegression_SigmoidFunction.png)\n",
    "\n",
    "In order to calculate the output of the logistic function we need to calculate the set of parameters $ \\theta $. This are calculated by training the logistic regressor, by minimising the cost function over the taining set.\n",
    "\n",
    "The process is know as a gradient descent. It works as follows:\n",
    "\n",
    "First, you initialize your parameters vector theta. Then you'd use the logistic function to get values for each of your observations. After that, you'd be able to calculate the gradients of your cost function and update your parameters. Finally, you'd be able to compute your cost J and determine if more iterations are needed according to a stop-parameter or maximum number of iterations.\n",
    "\n",
    "\n",
    "![Gradient Descent](Images/Training_Classifier.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\acastegnaro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk                         # NLP toolbox\n",
    "from os import getcwd\n",
    "import pandas as pd                 # Library for Dataframes \n",
    "from nltk.corpus import twitter_samples \n",
    "import matplotlib.pyplot as plt     # Library for visualization\n",
    "import numpy as np                  # Library for math functions\n",
    "\n",
    "from utils import process_tweet, build_freqs # Our functions for NLP\n",
    "\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NLTK sample dataset\n",
    "\n",
    "Sample dataset is the one used in the pre-processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tweets:  8000\n"
     ]
    }
   ],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# concatenating the tweets\n",
    "tweets = all_positive_tweets + all_negative_tweets\n",
    "# create labels\n",
    "labels = np.append(np.ones((len(all_positive_tweets),1)), np.zeros((len(all_negative_tweets),1)), axis = 0)\n",
    "\n",
    "# get a training set (arbitrary we are going to take the 40%)\n",
    "train_ratio = 0.80\n",
    "\n",
    "# Calculate the number of samples for the training set\n",
    "train_pos_size = int(len(all_positive_tweets) * train_ratio)\n",
    "train_neg_size = int(len(all_negative_tweets) * train_ratio)\n",
    "\n",
    "train_pos  = all_positive_tweets[:train_pos_size]\n",
    "train_neg  = all_negative_tweets[:train_neg_size]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "\n",
    "\n",
    "print(\"Number of training tweets: \", len(train_x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntlk_sentiment_analysis-qshMIsGW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
